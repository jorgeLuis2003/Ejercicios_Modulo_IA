{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #pip install numpy    se especializa en operaciones matematicas\n",
    "import pandas as pd #pip install pandas  pandas manipula datos\n",
    "import matplotlib.pyplot as plt #pip install matplotlib  se especializa con graficas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargar datos\n",
    "entrenamiento = pd.read_csv('Hipertension_Arterial_Mexico.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FOLIO_I</th>\n",
       "      <th>sexo</th>\n",
       "      <th>edad</th>\n",
       "      <th>concentracion_hemoglobina</th>\n",
       "      <th>temperatura_ambiente</th>\n",
       "      <th>valor_acido_urico</th>\n",
       "      <th>valor_albumina</th>\n",
       "      <th>valor_colesterol_hdl</th>\n",
       "      <th>valor_colesterol_ldl</th>\n",
       "      <th>valor_colesterol_total</th>\n",
       "      <th>...</th>\n",
       "      <th>segundamedicion_peso</th>\n",
       "      <th>segundamedicion_estatura</th>\n",
       "      <th>distancia_rodilla_talon</th>\n",
       "      <th>circunferencia_de_la_pantorrilla</th>\n",
       "      <th>segundamedicion_cintura</th>\n",
       "      <th>tension_arterial</th>\n",
       "      <th>sueno_horas</th>\n",
       "      <th>masa_corporal</th>\n",
       "      <th>actividad_total</th>\n",
       "      <th>riesgo_hipertension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022_01001004</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>14.2</td>\n",
       "      <td>22</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34</td>\n",
       "      <td>86.0</td>\n",
       "      <td>139</td>\n",
       "      <td>...</td>\n",
       "      <td>64.70</td>\n",
       "      <td>154.0</td>\n",
       "      <td>48.5</td>\n",
       "      <td>33.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>32.889389</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022_01001009</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>14.1</td>\n",
       "      <td>9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>73</td>\n",
       "      <td>130.0</td>\n",
       "      <td>252</td>\n",
       "      <td>...</td>\n",
       "      <td>96.75</td>\n",
       "      <td>152.2</td>\n",
       "      <td>44.5</td>\n",
       "      <td>41.1</td>\n",
       "      <td>113.7</td>\n",
       "      <td>104</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022_01001012</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>14.2</td>\n",
       "      <td>22</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34</td>\n",
       "      <td>86.0</td>\n",
       "      <td>139</td>\n",
       "      <td>...</td>\n",
       "      <td>68.70</td>\n",
       "      <td>144.8</td>\n",
       "      <td>42.3</td>\n",
       "      <td>37.8</td>\n",
       "      <td>103.7</td>\n",
       "      <td>105</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022_01001013</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>15.7</td>\n",
       "      <td>11</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>49</td>\n",
       "      <td>107.0</td>\n",
       "      <td>203</td>\n",
       "      <td>...</td>\n",
       "      <td>64.70</td>\n",
       "      <td>154.0</td>\n",
       "      <td>48.5</td>\n",
       "      <td>33.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117</td>\n",
       "      <td>5</td>\n",
       "      <td>26.265339</td>\n",
       "      <td>275</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022_01001015</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>12.7</td>\n",
       "      <td>7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>41</td>\n",
       "      <td>76.0</td>\n",
       "      <td>145</td>\n",
       "      <td>...</td>\n",
       "      <td>97.15</td>\n",
       "      <td>161.3</td>\n",
       "      <td>49.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>118.9</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         FOLIO_I  sexo  edad  concentracion_hemoglobina  temperatura_ambiente  \\\n",
       "0  2022_01001004     2    41                       14.2                    22   \n",
       "1  2022_01001009     2    65                       14.1                     9   \n",
       "2  2022_01001012     2    68                       14.2                    22   \n",
       "3  2022_01001013     1    35                       15.7                    11   \n",
       "4  2022_01001015     2    65                       12.7                     7   \n",
       "\n",
       "   valor_acido_urico  valor_albumina  valor_colesterol_hdl  \\\n",
       "0                4.8             4.0                    34   \n",
       "1                4.4             3.8                    73   \n",
       "2                4.8             4.0                    34   \n",
       "3                6.5             4.1                    49   \n",
       "4                4.2             4.2                    41   \n",
       "\n",
       "   valor_colesterol_ldl  valor_colesterol_total  ...  segundamedicion_peso  \\\n",
       "0                  86.0                     139  ...                 64.70   \n",
       "1                 130.0                     252  ...                 96.75   \n",
       "2                  86.0                     139  ...                 68.70   \n",
       "3                 107.0                     203  ...                 64.70   \n",
       "4                  76.0                     145  ...                 97.15   \n",
       "\n",
       "   segundamedicion_estatura  distancia_rodilla_talon  \\\n",
       "0                     154.0                     48.5   \n",
       "1                     152.2                     44.5   \n",
       "2                     144.8                     42.3   \n",
       "3                     154.0                     48.5   \n",
       "4                     161.3                     49.6   \n",
       "\n",
       "   circunferencia_de_la_pantorrilla  segundamedicion_cintura  \\\n",
       "0                              33.5                      0.0   \n",
       "1                              41.1                    113.7   \n",
       "2                              37.8                    103.7   \n",
       "3                              33.5                      0.0   \n",
       "4                              42.0                    118.9   \n",
       "\n",
       "   tension_arterial  sueno_horas  masa_corporal  actividad_total  \\\n",
       "0               107            4      32.889389              120   \n",
       "1               104            2       1.000000              240   \n",
       "2               105            1       1.000000              480   \n",
       "3               117            5      26.265339              275   \n",
       "4               123            2       1.000000              255   \n",
       "\n",
       "   riesgo_hipertension  \n",
       "0                    1  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    1  \n",
       "4                    0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entrenamiento.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#borramos columa inecesaria\n",
    "entrenamiento.drop('FOLIO_I',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separamos daatos de entrenamiento\n",
    "x=entrenamiento.drop('riesgo_hipertension',axis=1)\n",
    "y=entrenamiento['riesgo_hipertension']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separacion de datos de entrenamiento y datos de test\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y, test_size=0.2,random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sexo</th>\n",
       "      <th>edad</th>\n",
       "      <th>concentracion_hemoglobina</th>\n",
       "      <th>temperatura_ambiente</th>\n",
       "      <th>valor_acido_urico</th>\n",
       "      <th>valor_albumina</th>\n",
       "      <th>valor_colesterol_hdl</th>\n",
       "      <th>valor_colesterol_ldl</th>\n",
       "      <th>valor_colesterol_total</th>\n",
       "      <th>valor_creatina</th>\n",
       "      <th>...</th>\n",
       "      <th>medida_cintura</th>\n",
       "      <th>segundamedicion_peso</th>\n",
       "      <th>segundamedicion_estatura</th>\n",
       "      <th>distancia_rodilla_talon</th>\n",
       "      <th>circunferencia_de_la_pantorrilla</th>\n",
       "      <th>segundamedicion_cintura</th>\n",
       "      <th>tension_arterial</th>\n",
       "      <th>sueno_horas</th>\n",
       "      <th>masa_corporal</th>\n",
       "      <th>actividad_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>14.2</td>\n",
       "      <td>22</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34</td>\n",
       "      <td>86.0</td>\n",
       "      <td>139</td>\n",
       "      <td>0.58</td>\n",
       "      <td>...</td>\n",
       "      <td>104.5</td>\n",
       "      <td>64.70</td>\n",
       "      <td>154.0</td>\n",
       "      <td>48.5</td>\n",
       "      <td>33.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>34.508562</td>\n",
       "      <td>388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>14.2</td>\n",
       "      <td>22</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34</td>\n",
       "      <td>86.0</td>\n",
       "      <td>139</td>\n",
       "      <td>0.58</td>\n",
       "      <td>...</td>\n",
       "      <td>86.2</td>\n",
       "      <td>64.70</td>\n",
       "      <td>154.0</td>\n",
       "      <td>48.5</td>\n",
       "      <td>33.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132</td>\n",
       "      <td>3</td>\n",
       "      <td>22.216799</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3843</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>14.2</td>\n",
       "      <td>22</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34</td>\n",
       "      <td>86.0</td>\n",
       "      <td>139</td>\n",
       "      <td>0.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.70</td>\n",
       "      <td>154.0</td>\n",
       "      <td>48.5</td>\n",
       "      <td>33.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>17.081012</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>14.2</td>\n",
       "      <td>22</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34</td>\n",
       "      <td>86.0</td>\n",
       "      <td>139</td>\n",
       "      <td>0.58</td>\n",
       "      <td>...</td>\n",
       "      <td>106.7</td>\n",
       "      <td>64.70</td>\n",
       "      <td>154.0</td>\n",
       "      <td>48.5</td>\n",
       "      <td>33.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>31.730715</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>14.4</td>\n",
       "      <td>22</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>59</td>\n",
       "      <td>92.0</td>\n",
       "      <td>159</td>\n",
       "      <td>0.83</td>\n",
       "      <td>...</td>\n",
       "      <td>76.8</td>\n",
       "      <td>64.70</td>\n",
       "      <td>154.0</td>\n",
       "      <td>48.5</td>\n",
       "      <td>33.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "      <td>19.068380</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3234</th>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>14.2</td>\n",
       "      <td>22</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34</td>\n",
       "      <td>86.0</td>\n",
       "      <td>139</td>\n",
       "      <td>0.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.65</td>\n",
       "      <td>150.4</td>\n",
       "      <td>49.5</td>\n",
       "      <td>32.2</td>\n",
       "      <td>95.9</td>\n",
       "      <td>139</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>14.2</td>\n",
       "      <td>22</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34</td>\n",
       "      <td>86.0</td>\n",
       "      <td>139</td>\n",
       "      <td>0.58</td>\n",
       "      <td>...</td>\n",
       "      <td>87.6</td>\n",
       "      <td>64.70</td>\n",
       "      <td>154.0</td>\n",
       "      <td>48.5</td>\n",
       "      <td>33.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>104</td>\n",
       "      <td>4</td>\n",
       "      <td>24.461905</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3915</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>17.1</td>\n",
       "      <td>19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>31</td>\n",
       "      <td>34.0</td>\n",
       "      <td>68</td>\n",
       "      <td>0.77</td>\n",
       "      <td>...</td>\n",
       "      <td>77.6</td>\n",
       "      <td>64.70</td>\n",
       "      <td>154.0</td>\n",
       "      <td>48.5</td>\n",
       "      <td>33.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>19.996465</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>14.2</td>\n",
       "      <td>22</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34</td>\n",
       "      <td>86.0</td>\n",
       "      <td>139</td>\n",
       "      <td>0.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.90</td>\n",
       "      <td>154.9</td>\n",
       "      <td>50.0</td>\n",
       "      <td>37.2</td>\n",
       "      <td>109.8</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2522</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>14.2</td>\n",
       "      <td>22</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>34</td>\n",
       "      <td>86.0</td>\n",
       "      <td>139</td>\n",
       "      <td>0.58</td>\n",
       "      <td>...</td>\n",
       "      <td>119.3</td>\n",
       "      <td>64.70</td>\n",
       "      <td>154.0</td>\n",
       "      <td>48.5</td>\n",
       "      <td>33.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119</td>\n",
       "      <td>3</td>\n",
       "      <td>33.449655</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3490 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sexo  edad  concentracion_hemoglobina  temperatura_ambiente  \\\n",
       "1399     2    46                       14.2                    22   \n",
       "2475     1    22                       14.2                    22   \n",
       "3843     2    16                       14.2                    22   \n",
       "1075     1    54                       14.2                    22   \n",
       "184      1    31                       14.4                    22   \n",
       "...    ...   ...                        ...                   ...   \n",
       "3234     2    70                       14.2                    22   \n",
       "1607     2    27                       14.2                    22   \n",
       "3915     1    26                       17.1                    19   \n",
       "1428     2    66                       14.2                    22   \n",
       "2522     1    50                       14.2                    22   \n",
       "\n",
       "      valor_acido_urico  valor_albumina  valor_colesterol_hdl  \\\n",
       "1399                4.8             4.0                    34   \n",
       "2475                4.8             4.0                    34   \n",
       "3843                4.8             4.0                    34   \n",
       "1075                4.8             4.0                    34   \n",
       "184                 4.8             4.3                    59   \n",
       "...                 ...             ...                   ...   \n",
       "3234                4.8             4.0                    34   \n",
       "1607                4.8             4.0                    34   \n",
       "3915                4.0             3.5                    31   \n",
       "1428                4.8             4.0                    34   \n",
       "2522                4.8             4.0                    34   \n",
       "\n",
       "      valor_colesterol_ldl  valor_colesterol_total  valor_creatina  ...  \\\n",
       "1399                  86.0                     139            0.58  ...   \n",
       "2475                  86.0                     139            0.58  ...   \n",
       "3843                  86.0                     139            0.58  ...   \n",
       "1075                  86.0                     139            0.58  ...   \n",
       "184                   92.0                     159            0.83  ...   \n",
       "...                    ...                     ...             ...  ...   \n",
       "3234                  86.0                     139            0.58  ...   \n",
       "1607                  86.0                     139            0.58  ...   \n",
       "3915                  34.0                      68            0.77  ...   \n",
       "1428                  86.0                     139            0.58  ...   \n",
       "2522                  86.0                     139            0.58  ...   \n",
       "\n",
       "      medida_cintura  segundamedicion_peso  segundamedicion_estatura  \\\n",
       "1399           104.5                 64.70                     154.0   \n",
       "2475            86.2                 64.70                     154.0   \n",
       "3843             0.0                 64.70                     154.0   \n",
       "1075           106.7                 64.70                     154.0   \n",
       "184             76.8                 64.70                     154.0   \n",
       "...              ...                   ...                       ...   \n",
       "3234             0.0                 54.65                     150.4   \n",
       "1607            87.6                 64.70                     154.0   \n",
       "3915            77.6                 64.70                     154.0   \n",
       "1428             0.0                 82.90                     154.9   \n",
       "2522           119.3                 64.70                     154.0   \n",
       "\n",
       "      distancia_rodilla_talon  circunferencia_de_la_pantorrilla  \\\n",
       "1399                     48.5                              33.5   \n",
       "2475                     48.5                              33.5   \n",
       "3843                     48.5                              33.5   \n",
       "1075                     48.5                              33.5   \n",
       "184                      48.5                              33.5   \n",
       "...                       ...                               ...   \n",
       "3234                     49.5                              32.2   \n",
       "1607                     48.5                              33.5   \n",
       "3915                     48.5                              33.5   \n",
       "1428                     50.0                              37.2   \n",
       "2522                     48.5                              33.5   \n",
       "\n",
       "      segundamedicion_cintura  tension_arterial  sueno_horas  masa_corporal  \\\n",
       "1399                      0.0               106            3      34.508562   \n",
       "2475                      0.0               132            3      22.216799   \n",
       "3843                      0.0               115            1      17.081012   \n",
       "1075                      0.0               113            3      31.730715   \n",
       "184                       0.0               119            1      19.068380   \n",
       "...                       ...               ...          ...            ...   \n",
       "3234                     95.9               139            2       1.000000   \n",
       "1607                      0.0               104            4      24.461905   \n",
       "3915                      0.0               113            3      19.996465   \n",
       "1428                    109.8               135            1       1.000000   \n",
       "2522                      0.0               119            3      33.449655   \n",
       "\n",
       "      actividad_total  \n",
       "1399              388  \n",
       "2475              180  \n",
       "3843              570  \n",
       "1075              735  \n",
       "184               470  \n",
       "...               ...  \n",
       "3234              330  \n",
       "1607              240  \n",
       "3915              250  \n",
       "1428              320  \n",
       "2522              280  \n",
       "\n",
       "[3490 rows x 34 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1399    1\n",
       "2475    0\n",
       "3843    0\n",
       "1075    1\n",
       "184     0\n",
       "       ..\n",
       "3234    0\n",
       "1607    1\n",
       "3915    0\n",
       "1428    0\n",
       "2522    1\n",
       "Name: riesgo_hipertension, Length: 3490, dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler#importacion de librearia stANDAR SCALER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion para estandarizar los datos\n",
    "scaler = StandardScaler()\n",
    "x_train_scaler=scaler.fit_transform(x_train)\n",
    "x_test_scaler=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential #pip install tensorflow  trabaja con redes neuronales\n",
    "from tensorflow.keras.layers import Dense #importacion densidad (layers son capas y dense densidad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()#usamos un modelo secuensial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alumno\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(64,activation='relu',input_shape=(x_train.shape[1],)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creacion de red neuronal se le va agregar una capa de entrada\n",
    "#model.add(Dense(34,activation='relu',input_shape=(x_train.shape)))#capa de entrada donde 34 es la cantidad de entradas definido por la cantidad de columnas\n",
    "model.add(Dense(34,activation='relu'))#capas ocultas\n",
    "model.add(Dense(34,activation='relu'))#relu funcion de activacion para capas ocultas\n",
    "model.add(Dense(34,activation='relu'))\n",
    "model.add(Dense(34,activation='relu'))\n",
    "model.add(Dense(34,activation='relu'))\n",
    "model.add(Dense(34,activation='relu'))\n",
    "model.add(Dense(34,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1,activation='sigmoid'))#sigmoid se encarga de activar la funcion de resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compilar las red neuronal\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "#adam ajusta y optimiza los pesos y sesgos para buscar un resultado\n",
    "#binary_crossentropy establece errores o perdida de errores esclusivamente para funciones binarias\n",
    "#accuracy calcula la presicion del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6823 - loss: 0.7652 - val_accuracy: 0.8309 - val_loss: 0.3859\n",
      "Epoch 2/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7975 - loss: 0.4827 - val_accuracy: 0.8223 - val_loss: 0.4095\n",
      "Epoch 3/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8098 - loss: 0.4330 - val_accuracy: 0.8309 - val_loss: 0.3533\n",
      "Epoch 4/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8202 - loss: 0.4538 - val_accuracy: 0.8567 - val_loss: 0.3674\n",
      "Epoch 5/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8234 - loss: 0.3979 - val_accuracy: 0.8682 - val_loss: 0.3573\n",
      "Epoch 6/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8232 - loss: 0.4535 - val_accuracy: 0.8424 - val_loss: 0.3128\n",
      "Epoch 7/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8487 - loss: 0.4488 - val_accuracy: 0.7479 - val_loss: 0.5366\n",
      "Epoch 8/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8132 - loss: 0.4125 - val_accuracy: 0.8797 - val_loss: 0.2979\n",
      "Epoch 9/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8513 - loss: 0.3410 - val_accuracy: 0.8940 - val_loss: 0.2891\n",
      "Epoch 10/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8687 - loss: 0.3163 - val_accuracy: 0.8768 - val_loss: 0.2853\n",
      "Epoch 11/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8689 - loss: 0.3021 - val_accuracy: 0.8997 - val_loss: 0.2664\n",
      "Epoch 12/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8731 - loss: 0.3002 - val_accuracy: 0.8883 - val_loss: 0.2714\n",
      "Epoch 13/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8675 - loss: 0.3069 - val_accuracy: 0.8768 - val_loss: 0.2493\n",
      "Epoch 14/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8855 - loss: 0.2669 - val_accuracy: 0.8968 - val_loss: 0.2668\n",
      "Epoch 15/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8817 - loss: 0.2975 - val_accuracy: 0.8138 - val_loss: 0.4246\n",
      "Epoch 16/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8846 - loss: 0.2954 - val_accuracy: 0.8825 - val_loss: 0.2500\n",
      "Epoch 17/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9000 - loss: 0.2522 - val_accuracy: 0.8596 - val_loss: 0.3313\n",
      "Epoch 18/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8854 - loss: 0.3009 - val_accuracy: 0.8968 - val_loss: 0.2619\n",
      "Epoch 19/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8875 - loss: 0.2737 - val_accuracy: 0.9026 - val_loss: 0.2468\n",
      "Epoch 20/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8863 - loss: 0.2947 - val_accuracy: 0.9112 - val_loss: 0.2398\n",
      "Epoch 21/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9012 - loss: 0.2330 - val_accuracy: 0.8940 - val_loss: 0.2384\n",
      "Epoch 22/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8874 - loss: 0.2551 - val_accuracy: 0.9169 - val_loss: 0.2174\n",
      "Epoch 23/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9009 - loss: 0.2345 - val_accuracy: 0.8424 - val_loss: 0.3196\n",
      "Epoch 24/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8984 - loss: 0.2324 - val_accuracy: 0.9026 - val_loss: 0.3309\n",
      "Epoch 25/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8714 - loss: 0.3602 - val_accuracy: 0.8797 - val_loss: 0.2687\n",
      "Epoch 26/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8836 - loss: 0.2781 - val_accuracy: 0.8510 - val_loss: 0.2819\n",
      "Epoch 27/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8850 - loss: 0.2718 - val_accuracy: 0.9083 - val_loss: 0.2292\n",
      "Epoch 28/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8964 - loss: 0.2298 - val_accuracy: 0.8997 - val_loss: 0.2358\n",
      "Epoch 29/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8933 - loss: 0.2315 - val_accuracy: 0.9226 - val_loss: 0.2066\n",
      "Epoch 30/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9024 - loss: 0.2164 - val_accuracy: 0.9255 - val_loss: 0.1969\n",
      "Epoch 31/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9130 - loss: 0.2118 - val_accuracy: 0.9198 - val_loss: 0.2228\n",
      "Epoch 32/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9148 - loss: 0.2060 - val_accuracy: 0.9112 - val_loss: 0.2211\n",
      "Epoch 33/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9004 - loss: 0.2319 - val_accuracy: 0.9198 - val_loss: 0.1817\n",
      "Epoch 34/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9320 - loss: 0.1806 - val_accuracy: 0.8510 - val_loss: 0.3637\n",
      "Epoch 35/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9075 - loss: 0.2154 - val_accuracy: 0.9284 - val_loss: 0.2200\n",
      "Epoch 36/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9365 - loss: 0.1732 - val_accuracy: 0.9169 - val_loss: 0.1728\n",
      "Epoch 37/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.1798 - val_accuracy: 0.8883 - val_loss: 0.2148\n",
      "Epoch 38/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9298 - loss: 0.1571 - val_accuracy: 0.9026 - val_loss: 0.2334\n",
      "Epoch 39/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9286 - loss: 0.1786 - val_accuracy: 0.9398 - val_loss: 0.1601\n",
      "Epoch 40/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9279 - loss: 0.1840 - val_accuracy: 0.9169 - val_loss: 0.1714\n",
      "Epoch 41/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.1736 - val_accuracy: 0.9370 - val_loss: 0.1606\n",
      "Epoch 42/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9343 - loss: 0.1453 - val_accuracy: 0.9140 - val_loss: 0.1996\n",
      "Epoch 43/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9304 - loss: 0.1630 - val_accuracy: 0.9054 - val_loss: 0.2319\n",
      "Epoch 44/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9242 - loss: 0.1826 - val_accuracy: 0.9083 - val_loss: 0.1986\n",
      "Epoch 45/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9452 - loss: 0.1223 - val_accuracy: 0.9255 - val_loss: 0.1598\n",
      "Epoch 46/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9350 - loss: 0.1390 - val_accuracy: 0.8968 - val_loss: 0.2335\n",
      "Epoch 47/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9479 - loss: 0.1188 - val_accuracy: 0.9427 - val_loss: 0.1737\n",
      "Epoch 48/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9286 - loss: 0.1491 - val_accuracy: 0.9255 - val_loss: 0.1910\n",
      "Epoch 49/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9424 - loss: 0.1463 - val_accuracy: 0.9312 - val_loss: 0.1981\n",
      "Epoch 50/50\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9090 - loss: 0.1942 - val_accuracy: 0.9226 - val_loss: 0.1673\n"
     ]
    }
   ],
   "source": [
    "#entrenamiento de la red neuronal\n",
    "curva=model.fit(x_train,y_train,epochs=50,batch_size=32,validation_split=0.1)\n",
    "\n",
    "#epochs , epocas son la cantidad de veces que va estudiar el modelo , mientras mas epocas tenga el modelo mas va entrenar\n",
    "#batch_size inplica que cada n resultado va imprimir un resultado\n",
    "#validation_split es como un coheficiente de error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'#loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[138], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m# de epocas\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m# magnitud de perdida\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mcurva\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m#loss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[1;31mKeyError\u001b[0m: '#loss'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('# de epocas')\n",
    "plt.ylabel('# magnitud de perdida')\n",
    "plt.plot(curva.history['#loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    }
   ],
   "source": [
    "prediccion=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse=mean_squared_error(y_test,prediccion)#Error metrico cuadrado medio(MSE)\n",
    "mae=mean_absolute_error(y_test,prediccion)#Error absoluto medio(MAE)\n",
    "r2=r2_score(y_test,prediccion)#R cuadradoRL(R2)\n",
    "auc_roc = roc_auc_score(y_test,prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05537382957989355,\n",
       " 0.08398547259394024,\n",
       " 0.7529041093031601,\n",
       " 0.9826631223944916)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse,mae,r2,auc_roc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
